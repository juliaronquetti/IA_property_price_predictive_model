{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[{"file_id":"https://github.com/Rogerio-mack/IA_2024S1/blob/main/IA_2024S1_Projeto_Template.ipynb","timestamp":1716887501731}]}},"cells":[{"cell_type":"markdown","metadata":{"id":"40b90843"},"source":["<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">\n","<br>\n","<br>\n","<br>\n","<br>\n","<br>\n","\n","# ***Projecão Imobiliária na Cidade de São Paulo: Um Modelo Preditivo de Precificação***\n","---"]},{"cell_type":"code","metadata":{"id":"rYx9D4GZA5o9","cellView":"form","executionInfo":{"status":"ok","timestamp":1716887720469,"user_tz":180,"elapsed":343,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}}},"source":["#@title **Identificação do Grupo**\n","\n","#@markdown Integrantes do Grupo, nome completo em orgem alfabética (*informe \\<TIA\\>,\\<nome\\>*)\n","Aluno1 = '32139871, Júlia Ronquetti' #@param {type:\"string\"}\n","Aluno2 = 'None' #@param {type:\"string\"}\n","Aluno3 = 'None' #@param {type:\"string\"}\n","Aluno4 = 'None' #@param {type:\"string\"}\n","Aluno5 = 'None' #@param {type:\"string\"}\n","\n"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# **Resumo (*Abstract*)**\n","\n","Como podemos prever com precisão o preço de um imóvel em um mercado tão variável? O projeto trata esse desafio utilizando uma abordagem que combina dados quantitativos, qualitativos de imóveis da cidade de São Paulo, coletadas por meio da técnica de *Web Scraping*. Os dados foram extraídos da plataforma OLX, sendo dados originais. A partir desses dados, diversos algoritmos de aprendizado de máquina serão testados para determinar o mais eficaz na previsão de preços."],"metadata":{"id":"JlCIc2YooBW7"}},{"cell_type":"markdown","metadata":{"id":"A4-f8AtfKAn2"},"source":["# **Referencial Teórico**\n","\n","### Implicações Práticas e Comerciais\n","  Modelos de previsão de preço de imóveis não ajudam somente compradores e vendedores nas suas situações pontuais, mas também a utilização de modelos avançados, como descritos pelo autor [Gampala et al. 2022] permite  aos investidores identificar oportunidades de compra e venda com maior precisão. Isso significa decisões de investimento mais informadas e potencialmente mais lucrativas. A precisão melhorada ajuda a prevenir riscos e maximizar retornos, tornando o investimento em imóveis uma opção mais atrativa.\n","\n","  Além de melhorar as decisões de investimento, segundo o   [Anand et al. 2021], governos e autoridades locais podem utilizar os *insights* gerados por esses modelos para ajustar políticas de habitação e planejamento urbano. Isso inclui a determinação de áreas prioritárias para desenvolvimento, renovação ou mesmo para a implementação de controles de preço, evitando a especulação imobiliária e promovendo a acessibilidade habitacional.\n","\n","### Fundamentos de Modelos Preditivos no Mercado Imobiliário\n","A avaliação de preços de imóveis no Brasil é orientada pela Associação Brasileira de Normas Técnicas (ABNT) que recomenda o uso de modelos econométricos para a avaliação de propriedades urbanas (NBR 14653-2 – “Avaliação de imóveis urbanos”)  [Associacão Brasileira de Normas Técnicas (ABNT) 2011]. Os avaliadores seguem essa recomendação coletando dados de imóveis semelhantes ao objetivo, como apartamentos residenciais na mesma cidade, e evoluindo o preço com características como área, localização, número de quartos, entre outros. O modelo estimado é então usado para determinar o valor de mercado do imóvel em questão.\n","\n","Segundo o autor  [Marzagão et al. 2021], esse método ainda é muito utilizado, porém, é considerado falho, pois utiliza todas as amostras para ajustar a linha de regressão, sem deixar dados para testar o desempenho do modelo, o que não permite saber se os modelos criados são eficazes ou se são suposições aleatórias. Os autores argumentam que essa prática pode estabelecer grandes ineficiências no mercado, propondo em vez disso uma abordagem mais segura através de algoritmos de aprendizado de máquina, como árvores de decisão, máquinas de vetor de suporte e redes neurais, que podem descobrir padrões complexos nos dados e, potencialmente, oferecer predições mais precisas.\n","\n","O avanço das técnicas de aprendizado de máquina oferece novas oportunidades para aprimorar a precisão das avaliações de preços de imóveis. Os autores [Gampala et al. 2022] enfatizam a importância de testar uma variedade de modelos preditivos para avaliar qual deles apresenta melhor desempenho, destacando que algoritmos avançados, quando adequadamente treinados e validados, podem proporcionar estimativas de preços mais confiáveis. Este processo inclui a validação cruzada e a análise comparativa das métricas de desempenho, garantindo que os modelos não apenas se ajustem bem aos dados de treinamento, mas também generalizem de forma eficaz para novos dados. Com base nisso, compradores e vendedores podem tomar decisões mais informadas e estratégicas, facilitando operações mais eficientes e lucrativas no mercado imobiliário.\n","\n","### Web Scraping\n","O web scraping, também conhecido como extração de dados da web, é a técnica de coletar e processar dados automaticamente de websites. Essa técnica utiliza scripts ou ferramentas específicas para navegar em páginas da web, identificar e extrair informações relevantes, e armazená-las em um formato estruturado, como CSV, JSON ou banco de dados.\n","\n","O web scraping é uma ferramenta poderosa para diversos fins, como Análise de mercado, na extração de dados sobre preços, produtos, tendências e concorrentes; pesquisa científica, na coleta de dados para estudos e análises quantitativas e qualitativas; monitoramento de websites, no rastreamento de alterações em preços, produtos ou informações; e automação de tarefas, na realização repetitiva de tarefas em websites, como downloads de arquivos ou envio de formulários.\n","\n","Nesse trabalho, a técnica de web scraping foi utilizada para coletar dados de anúncios de imóveis no site OLX. Esses dados serão então utilizados para construir um modelo preditivo de preços de imóveis utilizando uma das técnicas de aprendizado de máquina mencionadas anteriormente. O modelo será avaliado em um conjunto de dados de validação para verificar sua precisão e generalização.\n","\n","### Modelos de Machine Learning\n","\n","A avaliação de imóveis é uma prática essencial no mercado imobiliário, sendo tradicionalmente realizada por meio de modelos de regressão linear. No entanto, essa abordagem tem se mostrado limitada e ineficiente devido à falta de testes de performance preditiva e à necessidade de hipóteses sobre a forma funcional do modelo [Marzagão et al., 2021]. Assim, o uso de algoritmos de aprendizado de máquina (*machine learning*) surge como uma alternativa promissora para melhorar a precisão e a eficiência das avaliações imobiliárias.\n","\n","O estudo critica a dependência excessiva na regressão linear, destacando vários pontos fracos dessa abordagem. Primeiro, os modelos de regressão linear não são testados com dados separados, o que pode resultar em previsões pouco confiáveis [Marzagão et al., 2021]. Além disso, esses modelos exigem a especificação prévia de uma forma funcional, o que é inadequado devido à complexidade das interações entre as variáveis no mercado imobiliário [Marzagão et al., 2021]. Outro problema é o potencial de overfitting, onde um alto valor de R² pode não refletir um bom desempenho preditivo em novos dados [Marzagão et al., 2021]."]},{"cell_type":"markdown","source":["# **Exemplo de Aplicação**\n","\n","Uma possível aplicação seria criar uma ferramenta que permita a estimativa de preços de imóveis com maior precisão ao integrar diversas características relevantes dos imóveis mais recentes. Este projeto aborda a aplicação de técnicas de aprendizado de máquina para analisar e prever preços com base em variáveis como localização, área útil, número de quartos, banheiros, entre outros.\n","\n","Neste contexto, um problema específico que será resolvido é a integração e a análise dos dados coletados através de web scraping da OLX. Utilizaremos técnicas de machine learning, como regressão linear e árvores de decisão, para construir e avaliar modelos preditivos que consigam capturar as tendências do mercado imobiliário com base nos dados coletados. A metodologia envolve a coleta e pré-processamento dos dados, a seleção e extração de features relevantes, o treinamento de modelos preditivos e a avaliação de sua performance.\n","\n","É esperado um resultado relevante, e se esse não se mostrar eficaz, vale o estudo para entender como melhorar no futuro."],"metadata":{"id":"4wfTEdMMxqFK"}},{"cell_type":"markdown","source":["# **Implementação**\n","\n","Coloque aqui o código da sua solução. Você deve explicar em linhas gerais o código. Para isso você pode quebrar o código em algumas partes e incluir células de texto explicativos. Não empregue para isso comentários no corpo do código, mas crie células de texto do notebook.\n","\n","Tente empregar exemplos que não sejam muito complexos e que busquem dar a você ou ao leitor um ponto de partida para o uso da tecnologia/conceito explorado.\n","\n","Ao final, se julgar útil, você pode ter uma célula com o código completo do que foi aqui dividido para explicar as diferentes partes."],"metadata":{"id":"FyFHbT8vygVp"}},{"cell_type":"markdown","source":["O Web Scraping foi utilizado na plataforma OLX, porém não foi possível rodar aqui no colab, apenas no VS Code por conta de algumas bibliotecas que são utilizadas.\n","Segue o código abaixo:"],"metadata":{"id":"lybnd-8X8lrZ"}},{"cell_type":"markdown","source":["## Web Scraping"],"metadata":{"id":"XebMm12gAwQb"}},{"cell_type":"markdown","source":["Importa bibliotecas necessárias"],"metadata":{"id":"FQKb_qdq-C7S"}},{"cell_type":"code","source":["import json\n","from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","import time\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time\n","import json\n","import re\n","import warnings\n","warnings.filterwarnings('ignore')\n","import datetime\n","import math\n","pd.set_option('display.max_columns', 100)"],"metadata":{"id":"nHZfrbYi9jI_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Configura e inicializa o navegador, obtém o HTML da página e converte para BeautifulSoup"],"metadata":{"id":"xnBzwEec_IbL"}},{"cell_type":"code","source":["def web_scrapping(url):\n","    chrome_service = Service(executable_path=r\"./chromedriver.exe\", log_path='NUL')\n","    chrome_options = webdriver.ChromeOptions()\n","\n","    # opções para ignorar erros de certificado\n","    chrome_options.add_argument('--ignore-certificate-errors')\n","    chrome_options.add_argument('--allow-running-insecure-content')\n","\n","    driver = webdriver.Chrome(service=chrome_service, options=chrome_options)\n","    driver.get(url)\n","    time.sleep(0.1)\n","    page_source = driver.page_source\n","    driver.quit()\n","    soup = BeautifulSoup(page_source, \"html.parser\")\n","    return soup\n"],"metadata":{"id":"47WSkdIDxpjM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Extrai dados JSON do HTML"],"metadata":{"id":"JgIxx5Qq_XS4"}},{"cell_type":"code","source":["def pegaJson(soup):\n","    # Encontrar o script com o ID '__NEXT_DATA__'\n","    next_data_script = soup.find('script', id='__NEXT_DATA__')\n","\n","    # Verificar se o script foi encontrado\n","    if next_data_script:\n","        # Carregar o JSON contido no script\n","        json_data = json.loads(next_data_script.string)\n","        return json_data\n","\n","    return None"],"metadata":{"id":"77g05PUv_aiS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Verifica e processa o HTML, extrai e estrutura os dados. Por mim, inclui em um dataframe"],"metadata":{"id":"pA9F__uD_eLc"}},{"cell_type":"code","source":["def dataframe(soup):\n","    if soup:\n","        # Encontrar a tag <script> e extrair o JSON diretamente como um objeto Python\n","        data = pegaJson(soup)  # Agora 'data' já é um objeto Python (dict) retornado por 'pegaJson'\n","        if data:\n","            # Acessar os anúncios diretamente do objeto Python\n","            ads = data['props']['pageProps']['ads']\n","            dados_imoveis = []\n","            for imovel in ads:\n","                dados_imovel = {\n","                    \"title\": imovel.get(\"title\", \"Sem título\"),\n","                    \"price\": imovel.get(\"price\", \"Sem Preço\"),\n","                    \"URL\" : imovel.get(\"url\", \"Sem URL\"),\n","                    \"oldPrice\": imovel.get(\"oldPrice\", \"Sem Preço\"),\n","                    \"location\": imovel.get(\"location\", \"Sem localização\"),\n","                    \"date\" : imovel.get(\"date\", 0),\n","                    \"imagem inicial\" : imovel.get(\"thumbnail\", \"Sem imagem\"),\n","                    \"images\": [img['original'] for img in imovel.get(\"images\", [])],\n","                    \"destaque\" : imovel.get(\"isFeatured\", \"Sem informação\"),\n","                }\n","                if 'properties' in imovel:\n","                    for prop in imovel[\"properties\"]:\n","                        if prop[\"label\"] == \"Categoria\":\n","                            dados_imovel[\"Categoria\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"Tipo\":\n","                            dados_imovel[\"Tipo\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"Condomínio\":\n","                            dados_imovel[\"Condomínio\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"IPTU\":\n","                            dados_imovel[\"IPTU\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"Área construída\":\n","                            dados_imovel[\"Área construída\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"Área útil\":\n","                            dados_imovel[\"Área útil\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"Quartos\":\n","                            dados_imovel[\"Quartos\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"Banheiros\":\n","                            dados_imovel[\"Banheiros\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"Vagas na garagem\":\n","                            dados_imovel[\"Vagas na garagem\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"Detalhes do imóvel\":\n","                            dados_imovel[\"Detalhes do imóvel\"] = prop.get(\"value\", \"Não informado\")\n","\n","                        elif prop[\"label\"] == \"Detalhes do condomínio\":\n","                            dados_imovel[\"Detalhes do condomínio\"] = prop.get(\"value\", \"Não informado\")\n","\n","                dados_imoveis.append(dados_imovel)\n","            df = pd.DataFrame(dados_imoveis)\n","            return df\n","        else:\n","            print(\"Não foi possível encontrar a tag <script> com o ID '__NEXT_DATA__'.\")\n","    else:\n","        print(\"Não foi possível fazer o scraping da página.\")\n"],"metadata":{"id":"UZLIKsRu_p2r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Coleta dados de múltiplas páginas e concatena os dataframes"],"metadata":{"id":"v4nbW8GP_0i1"}},{"cell_type":"code","source":["dfs = []\n","for page in range(1, 100):\n","    #Zona Oeste\n","    soup_zo = web_scrapping(f\"https://www.olx.com.br/imoveis/venda/estado-sp/sao-paulo-e-regiao/zona-oeste?o={page}\")\n","    df_zo = dataframe(soup_zo)\n","    df_zo['ZONA'] = 'OESTE'\n","    dfs.append(df_zo)\n","\n","    #Zona Leste\n","    soup_zl = web_scrapping(f\"https://www.olx.com.br/imoveis/venda/estado-sp/sao-paulo-e-regiao/zona-leste?o={page}\")\n","    df_zl = dataframe(soup_zl)\n","    df_zl['ZONA'] = 'LESTE'\n","    dfs.append(df_zl)\n","\n","    #Zona Sul\n","    soup_zs = web_scrapping(f\"https://www.olx.com.br/imoveis/venda/estado-sp/sao-paulo-e-regiao/zona-sul?o={page}\")\n","    df_zs = dataframe(soup_zs)\n","    df_zs['ZONA'] = 'SUL'\n","    dfs.append(df_zs)\n","\n","    #Zona Norte\n","    soup_zn = web_scrapping(f\"https://www.olx.com.br/imoveis/venda/estado-sp/sao-paulo-e-regiao/zona-norte?o={page}\")\n","    df_zn = dataframe(soup_zn)\n","    df_zn['ZONA'] = 'NORTE'\n","    dfs.append(df_zn)\n","\n","    #Zona Centro\n","    soup_zc = web_scrapping(f\"https://www.olx.com.br/imoveis/venda/estado-sp/sao-paulo-e-regiao/centro?o={page}\")\n","    df_zc = dataframe(soup_zc)\n","    df_zc['ZONA'] = 'CENTRO'\n","    dfs.append(df_zc)\n","\n","df = pd.concat(dfs, ignore_index=True)"],"metadata":{"id":"TSLw4enG_4Ln"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Tratamentos no dataframe"],"metadata":{"id":"BbKAIqRyAOFH"}},{"cell_type":"code","source":["# Convertendo a coluna 'images' que contém listas em strings\n","df['images'] = df['images'].apply(lambda x: str(x))\n","# Convertendo de volta para lista\n","# df['images'] = df['images'].apply(ast.literal_eval)\n","df_tratamentos = df.drop_duplicates()\n","df_tratamentos['date'] = df_tratamentos['date'].apply(lambda x: datetime.datetime.fromtimestamp(x, tz=datetime.timezone.utc).strftime('%d/%m/%Y'))\n","df_tratamentos['price'] = df_tratamentos['price'].replace({'R\\$ ': '', '\\.': ''}, regex=True)\n","df_tratamentos['oldPrice'] = df_tratamentos['oldPrice'].replace({'R\\$ ': '', '\\.': ''}, regex=True)\n","df_tratamentos['IPTU'] = df_tratamentos['IPTU'].replace({'R\\$ ': '', '\\.': ''}, regex=True)\n","df_tratamentos['Condomínio'] = df_tratamentos['Condomínio'].replace({'R\\$ ': '', '\\.': ''}, regex=True)\n","df_tratamentos['Área útil'].fillna(df_tratamentos['Área construída'], inplace=True)\n","df_tratamentos['Vagas na garagem'].fillna(0, inplace=True)\n","df_tratamentos.drop('Área construída', axis = 1, inplace=True)\n","\n","df_tratamentos = df_tratamentos[(~df_tratamentos.price.isna())].reset_index(drop=True)\n","df_tratamentos = df_tratamentos[(~df_tratamentos['Área útil'].isna())].reset_index(drop=True)\n","\n","df_tratamentos['Área útil'] = df_tratamentos['Área útil'].str.extract('(\\d+)', expand=False)\n","\n","imovel = df_tratamentos['Detalhes do imóvel'].str.split(',').explode().str.strip()\n","imovel = imovel.drop_duplicates().tolist()\n","imovel = [valor for valor in imovel if valor != \"nan\" and not (isinstance(valor, float) and math.isnan(valor))]\n","\n","condominio = df_tratamentos['Detalhes do condomínio'].str.split(',').explode().str.strip()\n","condominio = condominio.drop_duplicates().tolist()\n","condominio = [valor for valor in condominio if valor != \"nan\" and not (isinstance(valor, float) and math.isnan(valor))]\n","\n","def verificar_palavra(det, palavra):\n","    if pd.isnull(det) or not isinstance(det, str):\n","        return 0\n","    else:\n","        return 1 if palavra in det.split(', ') else 0\n","\n","for palavra in condominio:\n","    df_tratamentos[palavra] = df_tratamentos['Detalhes do condomínio'].apply(lambda x: verificar_palavra(x, palavra))\n","\n","for palavra in imovel:\n","    df_tratamentos[palavra] = df_tratamentos['Detalhes do imóvel'].apply(lambda x: verificar_palavra(x, palavra))\n","\n","#Bairro\n","df_tratamentos['bairro'] = df_tratamentos['location'].str.split(', ').str[1]\n","df_tratamentos['bairro'] = df_tratamentos['bairro'].str.replace(r\"\\s*\\(.*\\)\", \"\", regex=True)\n","\n"],"metadata":{"id":"byiVR6P1ASkf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Alguns outros tratamentos e modelos\n"],"metadata":{"id":"QyP2aFCoA7ZU"}},{"cell_type":"markdown","source":["Como não foi possível rodar no colab, importa o dataframe"],"metadata":{"id":"0EJ5YhImAbkt"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import pandas as pd\n","import numpy as np\n","pd.set_option('display.max_columns', 100)\n","import warnings\n","warnings.filterwarnings('ignore')\n","import os\n","import matplotlib.pyplot as plt\n","import gdown\n","import requests\n","\n","\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.svm import SVR\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MvOAa8mCAl0o","executionInfo":{"status":"ok","timestamp":1716951475418,"user_tz":180,"elapsed":2862,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}},"outputId":"a5f3e893-b5b1-44a0-f86f-9fe9cbedce04"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/IA Modelo preditivo/Dataframe_25_04.csv'\n","df = pd.read_csv(file_path, encoding = 'utf-8', sep=';')"],"metadata":{"id":"8yKyEOEaBWLE","executionInfo":{"status":"ok","timestamp":1716951687223,"user_tz":180,"elapsed":815,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["Não deu certo ler direto de um arquivo publico no drive, portanto o link do dataframe está aqui: https://drive.google.com/file/d/19llLrQtT5EJTYWRskRA-JUf1EAjJ7dbB/view?usp=sharing"],"metadata":{"id":"cONKjdYFS7JG"}},{"cell_type":"code","source":["url = 'https://drive.google.com/file/d/19llLrQtT5EJTYWRskRA-JUf1EAjJ7dbB/view?usp=sharing'\n","r = requests.get(url, allow_redirects=True)\n","\n","# Salve o arquivo\n","open('Dataframe_25_04.csv', 'wb').write(r.content)\n","\n","# Carregue o DataFrame\n","df = pd.read_csv('Dataframe_25_04.csv', encoding='utf-8', sep=';')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280},"id":"CcWKMTAZRU9X","executionInfo":{"status":"error","timestamp":1716951644211,"user_tz":180,"elapsed":748,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}},"outputId":"005e1313-a1fd-4424-bbd5-94dabb6f76e9"},"execution_count":25,"outputs":[{"output_type":"error","ename":"ParserError","evalue":"Error tokenizing data. C error: Expected 23 fields in line 59, saw 31\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-3297e0c911f9>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Carregue o DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataframe_25_04.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# # Coloque o link de compartilhamento aqui\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1702\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n","\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 23 fields in line 59, saw 31\n"]}]},{"cell_type":"markdown","source":["Realiza mais alguns tratamentos que foram necessários"],"metadata":{"id":"Mh-IJnhxBcJg"}},{"cell_type":"code","source":["campos_numericos = ['Condomínio', 'Área útil', 'Quartos', 'Banheiros', 'Vagas na garagem',\n","        'IPTU', 'Academia', 'Elevador', 'Permitido animais', 'Piscina', 'Portaria',\n","       'Salão de festas', 'Condomínio fechado', 'Segurança 24h',\n","       'Portão eletrônico', 'Área murada', 'Área de serviço',\n","       'Armários na cozinha', 'Armários no quarto', 'Churrasqueira',\n","       'Mobiliado', 'Quarto de serviço', 'Ar condicionado', 'Porteiro 24h',\n","       'Varanda']\n","\n","#Ajustar o 5 ou mais nos campos: Quartos, Banheiros, Vagas na garagem\n","df['Quartos'] = np.where(df['Quartos'] == '5 ou mais', 5, df['Quartos'])\n","df['Banheiros'] = np.where(df['Banheiros'] == '5 ou mais', 5, df['Banheiros'])\n","df['Vagas na garagem'] = np.where(df['Vagas na garagem'] == '5 ou mais', 5, df['Vagas na garagem'])\n","\n","#Fillna (0) nos campos numericos e transformar atributos object em int\n","df[campos_numericos] = df[campos_numericos].fillna(0).astype('int64')\n","#Ver o que fazer com os atributos de string\n"],"metadata":{"id":"rzzDeJE1BfYD","executionInfo":{"status":"ok","timestamp":1716947127982,"user_tz":180,"elapsed":985,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["Seleciona colunas que serão usadas no modelo, realiza o one-hot encoding e separa a base em treinamento e teste"],"metadata":{"id":"DAmBX9yLBlKf"}},{"cell_type":"code","source":["df_model = df[['price', 'Categoria', 'Tipo', 'destaque',\n","       'Condomínio', 'Área útil', 'Quartos', 'Banheiros', 'Vagas na garagem',\n","       'IPTU', 'ZONA',\n","       'Academia', 'Elevador', 'Permitido animais', 'Piscina', 'Portaria',\n","       'Salão de festas', 'Condomínio fechado', 'Segurança 24h',\n","       'Portão eletrônico', 'Área murada', 'Área de serviço',\n","       'Armários na cozinha', 'Armários no quarto', 'Churrasqueira',\n","       'Mobiliado', 'Quarto de serviço', 'Ar condicionado', 'Porteiro 24h',\n","       'Varanda', 'bairro']]\n","\n","df_model = pd.get_dummies(df_model, columns=['Categoria', 'Tipo', 'ZONA', 'bairro'], drop_first=True)\n","X = df_model.drop('price', axis = 1)\n","y = df_model.price\n","X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.25, random_state=123)"],"metadata":{"id":"mkErLvpfBkDC","executionInfo":{"status":"ok","timestamp":1716947354501,"user_tz":180,"elapsed":455,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["Treina diversos modelos e compara algumas métricas de avaliação"],"metadata":{"id":"4gchgoqlCMde"}},{"cell_type":"code","source":["modelos = {\n","    'Linear Regression': LinearRegression(),\n","    'Ridge Regression': Ridge(),\n","    'Lasso Regression': Lasso(),\n","    'Decision Tree': DecisionTreeRegressor(),\n","    'Random Forest': RandomForestRegressor(),\n","    'Gradient Boosting': GradientBoostingRegressor(),\n","    'Support Vector Regressor': SVR(),\n","    'K-Nearest Neighbors': KNeighborsRegressor()\n","}\n","\n","# Avaliar cada modelo\n","resultados = {}\n","for nome, modelo in modelos.items():\n","    modelo.fit(X_train, Y_train)\n","    y_pred = modelo.predict(X_test)\n","    mse = mean_squared_error(Y_test, y_pred)\n","    mae = mean_absolute_error(Y_test, y_pred)\n","    r2 = r2_score(Y_test, y_pred)\n","    resultados[nome] = {'MSE': mse, 'MAE': mae, 'R²': r2}\n","\n","# Exibir os resultados\n","resultados_df = pd.DataFrame(resultados).T\n","print(resultados_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OYgmNINdCVQE","executionInfo":{"status":"ok","timestamp":1716947927115,"user_tz":180,"elapsed":569752,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}},"outputId":"69e7f5f6-00ad-43a1-bc4e-b459dc5ca580"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["                                   MSE            MAE        R²\n","Linear Regression         1.571225e+12  601451.958935  0.527870\n","Ridge Regression          1.573476e+12  598216.613699  0.527194\n","Lasso Regression          1.570121e+12  600876.543281  0.528202\n","Decision Tree             1.153384e+12  340805.202673  0.653425\n","Random Forest             6.968856e+11  275396.454885  0.790596\n","Gradient Boosting         8.949052e+11  410264.869885  0.731094\n","Support Vector Regressor  3.577487e+12  876796.178874 -0.074981\n","K-Nearest Neighbors       1.265267e+12  422158.295853  0.619806\n"]}]},{"cell_type":"markdown","source":["O **Random Forest** apresenta o menor MSE e MAE, além de ter o maior valor de R², o que indica que é o modelo que melhor se ajusta aos dados e fornece as previsões mais precisas.\n","\n","Já o **Support Vector Regressor** apresenta o maior MSE e MAE, além de ter o menor valor de R², indicando que é o modelo que pior se ajusta aos dados e fornece as previsões menos precisas."],"metadata":{"id":"2N708egQDu6B"}},{"cell_type":"markdown","source":["# **Uma ideia de Projeto de Aplicação**\n","\n","Com a crescente disponibilidade de dados e o avanço das tecnologias de aprendizado de máquina, há uma oportunidade de desenvolver um sistema automatizado e atualizado frequentemente que possa fornecer avaliações de preços mais precisas e consistentes, ajudando a mitigar a subjetividade e as variações.\n","\n","Uma ideia de projeto seria dsenvolver um sistema inteligente de avaliação de preços de imóveis que utilize uma combinação de dados quantitativos e qualitativos. Este sistema empregará técnicas de aprendizado de máquina para analisar dados coletados de várias fontes, como sites de anúncios de imóveis, registros públicos e dados socioeconômicos. Esse modelo poderá ser disponibilizado também pelos próprios sites de divulgação de imóveis.\n","\n","Este sistema automatizado de avaliação de preços de imóveis pode trazer maior transparência e eficiência ao mercado imobiliário, fornecendo estimativas de preços mais precisas e baseadas em dados objetivos. Isso pode ajudar compradores a tomar decisões informadas e vendedores a definir preços competitivos, contribuindo para um mercado mais justo e equilibrado.\n"],"metadata":{"id":"vuisqDoJ0oTB"}},{"cell_type":"markdown","source":["# **Referências**\n","\n","Associacão Brasileira de Normas Técnicas (ABNT) (2011). Avaliacão de bens\n","parte 2: Imóveis urbanos. Norma Técnica NBR 14653-2. Disponível em:\n","https://www.prefeitura.sp.gov.br/cidade/secretarias/upload/infraestrutura/arquivos/ACESSO\n","\n","Marzagão, T., Ferreira, R., and Sales, L. (2021). A note on real estate appraisal in brazil.\n","Revista Brasileira de Economia, 75(1):29–36.\n","\n","Gampala, V., Sai, N. Y., and Sai Bhavya, T. N. (2022). Real-estate price prediction sys-\n","tem using machine learning. In 2022 International Conference on Applied Artificial\n","Intelligence and Computing (ICAAIC), pages 533–538\n","\n","S. P. Sreeja, V. Asha, B. Saju, N. CP, P. O. Prakash and A. K. Singh, \"Real Estate Price Prediction using Machine Learning,\" 2023 Third International Conference on Advances in Electrical, Computing, Communication and Sustainable Technologies (ICAECT), Bhilai, India, 2023, pp. 1-7, doi: 10.1109/ICAECT57570.2023.10117910.\n","\n","\n"],"metadata":{"id":"7LtXrRFr4hg3"}},{"cell_type":"markdown","source":["# **Vídeo e GitHub**\n","\n","https://youtu.be/hCQDEaEz62U"],"metadata":{"id":"ZGpU-v6CnTaG"}},{"cell_type":"markdown","metadata":{"id":"9kwoGZeSLRsX"},"source":["# **Conclusão**\n","\n","Este projeto de desenvolvimento de um sistema de avaliação de preços de imóveis apresenta uma abordagem baseada em dados originais para enfrentar um problema relevante e atual no mercado imobiliário. Utilizando técnicas de aprendizado de máquina o sistema proposto visa fornecer estimativas de preços consistentes, mitigando a subjetividade e a variação inerentes aos métodos tradicionais.\n","\n","Porém o modelo chegou em um resultado de R2 de 79% e com um MAE de 275396.45 usando o algoritmo Random Forest. Acredito que ainda conseguimos melhorar esse resultado. E um possível avanço para um resultado melhor poderia ser a utilização de imagens desses imóveis. No futuro, uma extensão promissora deste trabalho é a inclusão de imagens dos imóveis no modelo preditivo. Utilizando técnicas de visão computacional e deep learning, como redes neurais convolucionais (CNNs), será possível extrair características visuais significativas das imagens dos imóveis que impactam diretamente seu valor de mercado. A integração dessas características visuais com os dados quantitativos e qualitativos poderá aprimorar ainda mais a precisão das previsões, oferecendo um sistema de avaliação de preços ainda mais robusto e confiável.\n","\n","O autor realizou um projeto similar e alcançou um MAE de R$35,463.24, utilizando o mesmo algoritmo. Portanto, será interessante analizar como diminuir o MAE que alcancei.\n","\n"]},{"cell_type":"markdown","source":["# **Apêndice**\n","\n","Link da Apresentação no YouTube:\n"],"metadata":{"id":"EHohsrFbpksT"}},{"cell_type":"code","source":["from IPython.display import YouTubeVideo\n","YouTubeVideo('https://youtu.be/hCQDEaEz62U')\n","#https://youtu.be/hCQDEaEz62U"],"metadata":{"id":"LqJACWuip3YG","outputId":"6530a20a-126b-4333-e0c6-93385fa5ef28","colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"status":"ok","timestamp":1716955426051,"user_tz":180,"elapsed":369,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}}},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<IPython.lib.display.YouTubeVideo at 0x7ddcf2b87490>"],"text/html":["\n","        <iframe\n","            width=\"400\"\n","            height=\"300\"\n","            src=\"https://www.youtube.com/embed/https://youtu.be/hCQDEaEz62U\"\n","            frameborder=\"0\"\n","            allowfullscreen\n","            \n","        ></iframe>\n","        "]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"8crUBC3IQ3U_"},"source":["---"]},{"cell_type":"code","metadata":{"id":"BluFtfHuCGzm","cellView":"form","executionInfo":{"status":"ok","timestamp":1716887708813,"user_tz":180,"elapsed":316,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}}},"source":["#@title **Avaliação**\n","Referencial_Teorico = 4 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","Conceitos_Chave = 9 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","Exemplo_Aplicacao = 6 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","Ideia_Projeto = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","Conclusao = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n","\n","\n","\n","\n","\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":125},"id":"2Gqw7hUZHyle","cellView":"form","outputId":"b73351c5-a7bb-41c1-b512-98e02e1e3bbe","executionInfo":{"status":"ok","timestamp":1716887725336,"user_tz":180,"elapsed":892,"user":{"displayName":"Júlia Ronquetti Rodrigues","userId":"03469112362399672450"}}},"source":["#@title **Nota Final**\n","nota = Referencial_Teorico + Conceitos_Chave + 2*Exemplo_Aplicacao + 2*Ideia_Projeto + Conclusao\n","\n","nota = nota / 7\n","\n","print(f'Nota final do trabalho {nota :.1f}')\n","\n","import numpy as np\n","import pandas as pd\n","\n","alunos = pd.DataFrame()\n","\n","lista_tia = []\n","lista_nome = []\n","\n","for i in range(1,6):\n","  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n","\n","alunos['tia'] = lista_tia\n","alunos['nome'] = lista_nome\n","alunos['nota'] = np.round(nota,1)\n","print()\n","display(alunos)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Nota final do trabalho 7.4\n","\n"]},{"output_type":"display_data","data":{"text/plain":["        tia              nome  nota\n","0  32139871   JÚLIA RONQUETTI   7.4"],"text/html":["\n","  <div id=\"df-2c6f3014-10e6-4346-8561-dca8bbee774f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tia</th>\n","      <th>nome</th>\n","      <th>nota</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>32139871</td>\n","      <td>JÚLIA RONQUETTI</td>\n","      <td>7.4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c6f3014-10e6-4346-8561-dca8bbee774f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2c6f3014-10e6-4346-8561-dca8bbee774f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2c6f3014-10e6-4346-8561-dca8bbee774f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","  <div id=\"id_8590f439-ee80-4090-8c8d-835713fc7415\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('alunos')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_8590f439-ee80-4090-8c8d-835713fc7415 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('alunos');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"alunos","summary":"{\n  \"name\": \"alunos\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"tia\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"32139871\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nome\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \" J\\u00daLIA RONQUETTI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"nota\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 7.4,\n        \"max\": 7.4,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}}]}]}